---
title: "Normative retina sensitivity prediction"
subtitle: "For PHS 7045"
format:
  revealjs:
    slide-number: true
    embed-resources: true
    footer: "Yingjia Wei"
    code-annotations: below
    theme: ["default", "style.scss"]
highlight-style: espresso
author: 
  - '**Yingjia Wei**'
institute:
  - The University of Utah
date: 2024-12-12
aspectratio: 169
fig-format: svg
---

```{r}
#| label: preamble
#| echo: false
#| warning: false
#| message: false
library(data.table)
library(ggplot2)
library(NormalRetina)
```

# Introduction

## Hill-of-vision recap

![](fig/RetinaHoV.png){width="100%" fig-align="center"}

- Hill-of-vision: a graphical representation of retinal sensitivity, "peaks" represent areas of high sensitivity.

- We would like to use this hill-of-vision map to calculate standard sensitivity loss

## Difficulty: Age-adjusted normative data
**Conservative method: spatial interpolation**

- Spatial interpolation estimates sensitivity for a single virtual patient's testing results using Kriging.

- However, this approach may lose some population-level information and is harder to interpret.

**An interpretable age-adjusted prediction model would be much better!**

## Spacial interpolation

::: {.columns}
::: {.column width="50%"}

- Works with multiple exam types (e.g., Mesopic, Cyan, Red, and Cyan-Red difference).

- Provides predicted sensitivity values and visualizations with parallel computing.

- Kriging uses the best linear unbiased prediction based on both the spatial structure and the measurements, so it's not guaranteed to be the best prediction, especially in areas with sparse test points.

:::
::: {.column width="50%"}
```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "|9,12,14"
##----Interpolation----
data("ref77")
#head(ref77)

interpolated_77 <- Interpolation(dt = ref77, ncpus=NULL, cl=NULL)
## hill-of-vision from interpolation 
VisualRetina(pred_sens = interpolated_77[[2]], exam = unique(interpolated_77[[2]]$Examtype)) # plot mesopic results for comparison
```

```{r}
#| label: RMSE
#| eval: true
#| echo: false
knitr::kable(data.frame(ExamType=c("Mesopic", "Dark-adapted Cyan", "Dark-adapted Red", "Cyan-Red difference"), Model=c("Spherical", "Spherical", "Spherical", "Stable"), RMSE=c(0.3715, 0.9294, 0.5114, 0.9096), PartialSill=c(19,24,22,22), CorrDistance=c(6,6,10,8)), align = "l", format = "html") |>
  kableExtra::kable_styling(font_size = 15, position = "left", full_width = F)
```

![](../man/figures/README-example-2.png){width="80%" fig-align="left"}

:::
:::



# Extension
## Modelling age-adjusted normative data

- Objective: Predict retinal sensitivity based on patient-specific characteristics like age and test location.

- Models Used: 
  1. Linear Mixed Model (LMM), with age and eccentricity.
  
  2. Bayesian Quantile Regression (BQR), including an isotropic smooth (thin plate regression spline) for the x and y coordinate, a spline for the age and a tensor product smooth for age and eccentricity. 
  
  3. Random Forest (RF), using the variables: participant age, eye, eccentricity and angular distance from the fovea, and spatial coordinates (x,y).

- Performance comparison: mean absolute error (MAE) and mean absolute calibration error (MACE), with patient-wise cross-validation and conformal prediction frameworks.


## Workflow

::: {.columns}
::: {.column width="50%"}
- **Step 1: Data preparation**: `SensForFit()`
- **Step 2: Model performance comparison**: `PredictCompare()`
  - also specific functions: `PredictNormal_lmm()`, `PredictNormal_bqr()`, `PredictNormal_rf()`


- **Step 3: Prediction based on optimal model**: `PredictSensitivity()`
- **Step 4: Visualization**: `VisualRetina()`

:::
::: {.column width="50%"}
```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "|9,12,14"
data("refMes")
## data preparation
refMes <- SensForFit(dt = refMes, examcol = "Examtype", idcol = "Patient", agecol = "Age", senscol = "MeanSens", k = 10)
## model comparison
(res.tab <- PredictCompare(dt = refMes, exam = "Mesopic", CalibSplit = 0.2, coverage = 0.95))
## prediction for a future patient aged 77 (e.g. bqr is the best)
pred_BQR_77 <- PredictSensitivity(model = "BQR", age = 77, dt = refMes)
## hill-of-vision for new patient
VisualRetina(pred_sens = pred_BQR_77, exam = "Mesopic")
```
  
```{r, eval=TRUE, echo=FALSE}
load(file="~/Desktop/Fall 24/PHS 7045 R Programming/PHS 7045 first project/PHS_final_package/misc/res_tab.Rdata")
res.tab |> data.frame() |> 
  dplyr::mutate(MAE=as.numeric(MAE),
                MACE=as.numeric(MACE)) |> knitr::kable(digits = 2)
```
![](../man/figures/README-example-1.png){width="70%" fig-align="left"}

:::
:::

## Discussion

**Other Models vs. Interpolation**

- Models provide insights into age and test-location effects on sensitivity.

- No need to predict complete hill-of-vision.

- Models can account for variability across patients and test sites.

- Further exploration is needed to develop a robust conformal prediction framework, especially for machine learning methods.

## Reference
- [1] Pfau, M., Jolly, J. K., Charng, J., von der Emde, L., Müller, P. L., Ansari, G., Pfau, K., Chen, F. K., & Wu, Z. (2024). Multicenter normative data for mesopic microperimetry. Investigative Ophthalmology & Visual Science, 65(12), Article 27. https://doi.org/10.1167/iovs.65.12.27

- [2] Pfau, M., Müller, P. L., von der Emde, L., Lindner, M., Möller, P. T., Fleckenstein, M., Holz, F. G., & Schmitz-Valckenberg, S. (2020). Mesopic and dark-adapted two-color fundus-controlled perimetry in geographic atrophy secondary to age-related macular degeneration. Retina, 40(1), 169–180. https://doi.org/10.1097/IAE.0000000000002337

- [3] Angelopoulos, A. N., & Bates, S. (2021). A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification. arXiv. https://doi.org/10.48550/arXiv.2107.07511

- [4] Johansson, U., Boström, H., Löfström, T. et al. Regression conformal prediction with random forests. Mach Learn 97, 155–176 (2014). https://doi.org/10.1007/s10994-014-5453-0

## Thanks!


